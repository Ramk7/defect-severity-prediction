Fri Mar 15 08:23:38 2019
-----EXPERIMENT  1  START-----
Dataset:  ../dataset/raw/pitsA.csv
 
Fold:  1
Average
Precision | Recall | F-Score
(0.5579097618428815, 0.38144329896907214, 0.41760164494314805, None)

By Severity
Precision | Recall | F-Score
(array([0.33333333, 0.70588235, 0.18367347, 0.        ]),
 array([0.4       , 0.35820896, 0.47368421, 0.        ]),
 array([0.36363636, 0.47524752, 0.26470588, 0.        ]),
 array([10, 67, 19,  1]))
 
Fold:  2
Average
Precision | Recall | F-Score
(0.6776710402999063, 0.6288659793814433, 0.6496268698560359, None)

By Severity
Precision | Recall | F-Score
(array([0.3       , 0.828125  , 0.22727273, 0.        ]),
 array([0.33333333, 0.73611111, 0.33333333, 0.        ]),
 array([0.31578947, 0.77941176, 0.27027027, 0.        ]),
 array([ 9, 72, 15,  1]))
 
Fold:  3
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.7923994340004042, 0.7938144329896907, 0.7771255693122214, None)

By Severity
Precision | Recall | F-Score
(array([0.89411765, 0.33333333, 0.        , 0.        ]),
 array([0.95  , 0.0625, 0.    , 0.    ]),
 array([0.92121212, 0.10526316, 0.        , 0.        ]),
 array([80, 16,  0,  1]))
 
Fold:  4
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.9480981158905084, 0.9175257731958762, 0.9325528568932379, None)

By Severity
Precision | Recall | F-Score
(array([0.98850575, 0.5       , 0.        , 0.        ]),
 array([0.95555556, 0.5       , 0.        , 0.        ]),
 array([0.97175141, 0.5       , 0.        , 0.        ]),
 array([90,  6,  1,  0]))
 
Fold:  5
Average
Precision | Recall | F-Score
(0.7063492063492063, 0.5773195876288659, 0.6313991163475698, None)

By Severity
Precision | Recall | F-Score
(array([0.72222222, 0.80392157, 0.14285714, 0.        ]),
 array([0.76470588, 0.60294118, 0.18181818, 0.        ]),
 array([0.74285714, 0.68907563, 0.16      , 0.        ]),
 array([17, 68, 11,  1]))
 
Fold:  6
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.4272604875283446, 0.375, 0.37529668267373184, None)

By Severity
Precision | Recall | F-Score
(array([0.38095238, 0.36734694, 0.5       , 0.        ]),
 array([0.34782609, 0.5625    , 0.24390244, 0.        ]),
 array([0.36363636, 0.44444444, 0.32786885, 0.        ]),
 array([23, 32, 41,  0]))
 
Fold:  7
Average
Precision | Recall | F-Score
(0.4169542213020474, 0.3229166666666667, 0.3396811367530419, None)

By Severity
Precision | Recall | F-Score
(array([0.10714286, 0.52173913, 0.30555556, 0.55555556]),
 array([0.27272727, 0.25      , 0.40740741, 0.5       ]),
 array([0.15384615, 0.33802817, 0.34920635, 0.52631579]),
 array([11, 48, 27, 10]))
 
Fold:  8
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.7837301587301587, 0.3020833333333333, 0.3598276494316098, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.17857143, 0.9047619 , 0.        ]),
 array([0.    , 0.625 , 0.2375, 0.    ]),
 array([0.        , 0.27777778, 0.37623762, 0.        ]),
 array([ 0, 16, 80,  0]))
 
Fold:  9
Average
Precision | Recall | F-Score
(0.5596509971509972, 0.4583333333333333, 0.4732815915072038, None)

By Severity
Precision | Recall | F-Score
(array([0.875     , 0.38888889, 0.07692308, 0.        ]),
 array([0.53846154, 0.82352941, 0.0952381 , 0.        ]),
 array([0.66666667, 0.52830189, 0.08510638, 0.        ]),
 array([52, 17, 21,  6]))
 
Fold:  10
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.5403645833333334, 0.5520833333333334, 0.5316873902934393, None)

By Severity
Precision | Recall | F-Score
(array([0.70833333, 0.5       , 0.5       , 0.        ]),
 array([0.51515152, 0.75757576, 0.45833333, 0.        ]),
 array([0.59649123, 0.60240964, 0.47826087, 0.        ]),
 array([33, 33, 24,  6]))
-----EXPERIMENT  1  END-------

-----EXPERIMENT  2  START-----
Dataset:  ../dataset/raw/pitsB.csv
 
Fold:  1
Average
Precision | Recall | F-Score
(0.6467069686766657, 0.494949494949495, 0.49996106491776043, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.875     , 0.41269841, 0.18181818]),
 array([0.        , 0.38181818, 0.74285714, 0.25      ]),
 array([0.        , 0.53164557, 0.53061224, 0.21052632]),
 array([ 1, 55, 35,  8]))
 
Fold:  2
Average
Precision | Recall | F-Score
(0.553247600568528, 0.45454545454545453, 0.45885779134595905, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.45283019, 0.73913043, 0.21052632]),
 array([0.        , 0.70588235, 0.34693878, 0.26666667]),
 array([0.        , 0.55172414, 0.47222222, 0.23529412]),
 array([ 1, 34, 49, 15]))
 
Fold:  3
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.6698347107438016, 0.6565656565656566, 0.6623083881866662, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.8       , 0.45454545, 0.375     ]),
 array([0.    , 0.8125, 0.4   , 0.3   ]),
 array([0.        , 0.80620155, 0.42553191, 0.33333333]),
 array([ 0, 64, 25, 10]))
 
Fold:  4
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.5036645203203715, 0.5353535353535354, 0.5081051458419354, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.6119403 , 0.43478261, 0.22222222]),
 array([0.        , 0.77358491, 0.27777778, 0.25      ]),
 array([0.        , 0.68333333, 0.33898305, 0.23529412]),
 array([ 2, 53, 36,  8]))
 
Fold:  5
Average
Precision | Recall | F-Score
(0.4123675782212367, 0.3838383838383838, 0.3914862914862915, None)

By Severity
Precision | Recall | F-Score
(array([0.1       , 0.46341463, 0.37777778, 0.33333333]),
 array([0.25      , 0.35185185, 0.43589744, 0.5       ]),
 array([0.14285714, 0.4       , 0.4047619 , 0.4       ]),
 array([ 4, 54, 39,  2]))
 
Fold:  6
Average
Precision | Recall | F-Score
(0.6591309924643256, 0.5858585858585859, 0.599876534635893, None)

By Severity
Precision | Recall | F-Score
(array([0.88888889, 0.57142857, 0.77777778, 0.07142857]),
 array([0.66666667, 0.77777778, 0.48837209, 0.125     ]),
 array([0.76190476, 0.65882353, 0.6       , 0.09090909]),
 array([12, 36, 43,  8]))
 
Fold:  7
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.6170850559036213, 0.6464646464646465, 0.6230491336874316, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.70886076, 0.44444444, 0.        ]),
 array([0.        , 0.82352941, 0.27586207, 0.        ]),
 array([0.        , 0.76190476, 0.34042553, 0.        ]),
 array([ 2, 68, 29,  0]))
 
Fold:  8
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.7454441776710685, 0.7244897959183674, 0.7318807222136976, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.80882353, 0.64      , 0.        ]),
 array([0.        , 0.84615385, 0.5       , 0.        ]),
 array([0.        , 0.82706767, 0.56140351, 0.        ]),
 array([ 0, 65, 32,  1]))
 
Fold:  9
Average
Precision | Recall | F-Score
(0.5498608534322821, 0.42857142857142855, 0.446625881473871, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.36363636, 0.6875    , 0.2       ]),
 array([0.        , 0.5       , 0.36666667, 0.8       ]),
 array([0.        , 0.42105263, 0.47826087, 0.32      ]),
 array([ 1, 32, 60,  5]))
 
Fold:  10
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.7028488082697629, 0.5816326530612245, 0.6216628625980717, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.80487805, 0.55813953, 0.        ]),
 array([0.        , 0.53225806, 0.70588235, 0.        ]),
 array([0.        , 0.6407767 , 0.62337662, 0.        ]),
 array([ 0, 62, 34,  2]))
-----EXPERIMENT  2  END-------

-----EXPERIMENT  3  START-----
Dataset:  ../dataset/raw/pitsC.csv
 
Fold:  1
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.9008264462809917, 0.7272727272727273, 0.7955957086391868, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 1.        , 0.86363636, 0.        ]),
 array([0.        , 0.55555556, 0.79166667, 0.        ]),
 array([0.        , 0.71428571, 0.82608696, 0.        ]),
 array([ 0,  9, 24,  0]))
 
Fold:  2
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(1.0, 0.9696969696969697, 0.9846153846153846, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 0., 1., 0.]),
 array([0.        , 0.        , 0.96969697, 0.        ]),
 array([0.        , 0.        , 0.98461538, 0.        ]),
 array([ 0,  0, 33,  0]))
 
Fold:  3
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.47865612648221345, 0.5454545454545454, 0.4920414485631877, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.7       , 0.47826087, 0.        ]),
 array([0.        , 0.53846154, 0.78571429, 0.        ]),
 array([0.        , 0.60869565, 0.59459459, 0.        ]),
 array([ 0, 13, 14,  6]))
 
Fold:  4
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.8212890625, 0.90625, 0.8616803278688524, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.     , 0.90625, 0.     , 0.     ]),
 array([0., 1., 0., 0.]),
 array([0.        , 0.95081967, 0.        , 0.        ]),
 array([ 0, 29,  3,  0]))
 
Fold:  5
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(1.0, 0.96875, 0.9841269841269841, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0.     , 0.96875, 0.     , 0.     ]),
 array([0.        , 0.98412698, 0.        , 0.        ]),
 array([ 0, 32,  0,  0]))
 
Fold:  6
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.7855603448275862, 0.84375, 0.8136160714285714, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.93103448, 0.        , 0.        ]),
 array([0., 1., 0., 0.]),
 array([0.        , 0.96428571, 0.        , 0.        ]),
 array([ 0, 27,  5,  0]))
 
Fold:  7
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.712215909090909, 0.71875, 0.7003205128205128, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.8       , 0.68181818, 0.        ]),
 array([0.        , 0.57142857, 0.88235294, 0.        ]),
 array([0.        , 0.66666667, 0.76923077, 0.        ]),
 array([ 0, 14, 17,  1]))
 
Fold:  8
Average
Precision | Recall | F-Score
(0.9139285714285714, 0.90625, 0.9089366515837103, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.71428571, 0.96      , 0.        ]),
 array([0.        , 0.83333333, 0.92307692, 0.        ]),
 array([0.        , 0.76923077, 0.94117647, 0.        ]),
 array([ 0,  6, 26,  0]))
 
Fold:  9
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.87890625, 0.9375, 0.907258064516129, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.    , 0.    , 0.9375, 0.    ]),
 array([0., 0., 1., 0.]),
 array([0.        , 0.        , 0.96774194, 0.        ]),
 array([ 0,  2, 30,  0]))
 
Fold:  10
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.8760416666666667, 0.90625, 0.8908898305084745, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.        , 0.96666667, 0.        ]),
 array([0., 0., 1., 0.]),
 array([0.        , 0.        , 0.98305085, 0.        ]),
 array([ 0,  1, 29,  2]))
-----EXPERIMENT  3  END-------

-----EXPERIMENT  4  START-----
Dataset:  ../dataset/raw/pitsD.csv
 
Fold:  1
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.8278195488721805, 0.8421052631578947, 0.8262250453720509, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.92857143, 0.6       , 0.        ]),
 array([0.        , 0.86666667, 1.        , 0.        ]),
 array([0.        , 0.89655172, 0.75      , 0.        ]),
 array([ 1, 15,  3,  0]))
 
Fold:  2
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.335180055401662, 0.5789473684210527, 0.4245614035087719, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.57894737, 0.        , 0.        ]),
 array([0., 1., 0., 0.]),
 array([0.        , 0.73333333, 0.        , 0.        ]),
 array([ 0, 11,  8,  0]))
 
Fold:  3
Average
Precision | Recall | F-Score
(0.9444444444444444, 0.8888888888888888, 0.9037037037037037, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0. , 1. , 0.5, 0. ]),
 array([0.   , 0.875, 1.   , 0.   ]),
 array([0.        , 0.93333333, 0.66666667, 0.        ]),
 array([ 0, 16,  2,  0]))
 
Fold:  4
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.9444444444444444, 0.8333333333333334, 0.8854166666666666, None)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0.        , 0.88235294, 0.        , 0.        ]),
 array([0.    , 0.9375, 0.    , 0.    ]),
 array([ 0, 17,  0,  1]))
 
Fold:  5
Average
Precision | Recall | F-Score
(1.0, 1.0, 1.0, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([ 0, 18,  0,  0]))
 
Fold:  6
Average
Precision | Recall | F-Score
(1.0, 1.0, 1.0, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([ 0, 18,  0,  0]))
 
Fold:  7
Average
Precision | Recall | F-Score
(1.0, 1.0, 1.0, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([ 0, 18,  0,  0]))
 
Fold:  8
Average
Precision | Recall | F-Score
(1.0, 1.0, 1.0, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([ 0, 18,  0,  0]))
 
Fold:  9
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(1.0, 0.9444444444444444, 0.9714285714285713, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0.        , 0.94444444, 0.        , 0.        ]),
 array([0.        , 0.97142857, 0.        , 0.        ]),
 array([ 0, 18,  0,  0]))
 
Fold:  10
Average
Precision | Recall | F-Score
(1.0, 1.0, 1.0, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([0., 1., 0., 0.]),
 array([ 0, 18,  0,  0]))
-----EXPERIMENT  4  END-------

-----EXPERIMENT  5  START-----
Dataset:  ../dataset/raw/pitsE.csv
 
Fold:  1
Average
Precision | Recall | F-Score
(0.5773902059852313, 0.5421686746987951, 0.5290431675769292, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.64516129, 0.625     , 0.        ]),
 array([0.        , 0.76923077, 0.2173913 , 0.        ]),
 array([0.        , 0.70175439, 0.32258065, 0.        ]),
 array([ 5, 52, 23,  3]))
 
Fold:  2
Average
Precision | Recall | F-Score
(0.6249922767995059, 0.37349397590361444, 0.4197234142047642, None)

By Severity
Precision | Recall | F-Score
(array([0.16666667, 0.35897436, 0.8       , 0.        ]),
 array([0.33333333, 0.56      , 0.30188679, 0.        ]),
 array([0.22222222, 0.4375    , 0.43835616, 0.        ]),
 array([ 3, 25, 53,  2]))
 
Fold:  3
Average
Precision | Recall | F-Score
(0.5152076838823827, 0.5903614457831325, 0.5496522676070135, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.72727273, 0.07692308, 0.        ]),
 array([0.        , 0.84210526, 0.05882353, 0.        ]),
 array([0.        , 0.7804878 , 0.06666667, 0.        ]),
 array([ 2, 57, 17,  7]))
 
Fold:  4
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.6166404749432512, 0.7108433734939759, 0.6478940555610874, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.72463768, 0.75      , 0.        ]),
 array([0.        , 0.96153846, 0.5       , 0.        ]),
 array([0.        , 0.82644628, 0.6       , 0.        ]),
 array([ 5, 52, 18,  8]))
 
Fold:  5
Average
Precision | Recall | F-Score
(0.6278474220769719, 0.5301204819277109, 0.5745327173355074, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.82692308, 0.05263158, 0.        ]),
 array([0.        , 0.69354839, 0.0625    , 0.        ]),
 array([0.        , 0.75438596, 0.05714286, 0.        ]),
 array([ 1, 62, 16,  4]))
 
Fold:  6
Average
Precision | Recall | F-Score
(0.5906165311653117, 0.6707317073170732, 0.6170439130781712, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.73611111, 0.25      , 0.        ]),
 array([0.        , 0.89830508, 0.1       , 0.        ]),
 array([0.        , 0.80916031, 0.14285714, 0.        ]),
 array([ 2, 59, 20,  1]))
 
Fold:  7
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.40868275977280316, 0.5487804878048781, 0.4550635959321266, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.60273973, 0.125     , 0.        ]),
 array([0.        , 0.88      , 0.03703704, 0.        ]),
 array([0.        , 0.71544715, 0.05714286, 0.        ]),
 array([ 2, 50, 27,  3]))
 
Fold:  8
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.5082678792889624, 0.573170731707317, 0.5346487191287007, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.61016949, 0.5       , 0.        ]),
 array([0.        , 0.76595745, 0.42307692, 0.        ]),
 array([0.        , 0.67924528, 0.45833333, 0.        ]),
 array([ 3, 47, 26,  6]))
 
Fold:  9
Average
Precision | Recall | F-Score
(0.6144018583042973, 0.6585365853658537, 0.6245713916025102, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.72857143, 0.33333333, 0.        ]),
 array([0.  , 0.85, 0.15, 0.  ]),
 array([0.        , 0.78461538, 0.20689655, 0.        ]),
 array([ 1, 60, 20,  1]))
 
Fold:  10
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.40603502188868046, 0.5975609756097561, 0.48352262148575686, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.62820513, 0.        , 0.        ]),
 array([0.       , 0.9245283, 0.       , 0.       ]),
 array([0.       , 0.7480916, 0.       , 0.       ]),
 array([ 0, 53, 23,  6]))
-----EXPERIMENT  5  END-------

-----EXPERIMENT  6  START-----
Dataset:  ../dataset/raw/pitsF.csv
 
Fold:  1
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.9095873015873015, 0.8133333333333334, 0.8577611940298506, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.95238095, 0.2       , 0.        ]),
 array([0.        , 0.84507042, 0.33333333, 0.        ]),
 array([0.        , 0.89552239, 0.25      , 0.        ]),
 array([ 0, 71,  3,  1]))
 
Fold:  2
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.9881481481481482, 0.5066666666666667, 0.6604444444444444, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 1.        , 0.11111111, 0.        ]),
 array([0. , 0.5, 1. , 0. ]),
 array([0.        , 0.66666667, 0.2       , 0.        ]),
 array([ 0, 74,  1,  0]))
 
Fold:  3
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.4816666666666667, 0.4533333333333333, 0.46177304964539007, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.60416667, 0.33333333, 0.        ]),
 array([0.        , 0.63043478, 0.2       , 0.        ]),
 array([0.        , 0.61702128, 0.25      , 0.        ]),
 array([ 4, 46, 25,  0]))
 
Fold:  4
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.6946666666666667, 0.68, 0.6860317460317461, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.8       , 0.35294118, 0.5       ]),
 array([0.        , 0.77192982, 0.35294118, 1.        ]),
 array([0.        , 0.78571429, 0.35294118, 0.66666667]),
 array([ 0, 57, 17,  1]))
 
Fold:  5
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.39932789932789936, 0.44594594594594594, 0.4184384384384384, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.57407407, 0.14285714, 0.        ]),
 array([0.        , 0.67391304, 0.09090909, 0.        ]),
 array([0.        , 0.62      , 0.11111111, 0.        ]),
 array([ 0, 46, 22,  6]))
 
Fold:  6
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.1529386529386529, 0.3108108108108108, 0.20500287521564117, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.36507937, 0.        , 0.        ]),
 array([0.        , 0.74193548, 0.        , 0.        ]),
 array([0.       , 0.4893617, 0.       , 0.       ]),
 array([ 1, 31, 14, 28]))
 
Fold:  7
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.4743769743769744, 0.527027027027027, 0.4333047049035132, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.54545455, 0.42857143, 0.        ]),
 array([0.        , 0.9       , 0.09677419, 0.        ]),
 array([0.        , 0.67924528, 0.15789474, 0.        ]),
 array([ 1, 40, 31,  1]))
 
Fold:  8
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
Average
Precision | Recall | F-Score
(0.5678490990990991, 0.5540540540540541, 0.5608577228606683, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.6875    , 0.33333333, 0.        ]),
 array([0.        , 0.67346939, 0.32      , 0.        ]),
 array([0.        , 0.68041237, 0.32653061, 0.        ]),
 array([ 0, 49, 25,  0]))
 
Fold:  9
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Average
Precision | Recall | F-Score
(0.340859493033406, 0.25675675675675674, 0.2361003861003861, None)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.28571429, 0.44444444, 0.13043478]),
 array([0.        , 0.4       , 0.11111111, 0.6       ]),
 array([0.        , 0.33333333, 0.17777778, 0.21428571]),
 array([ 3, 30, 36,  5]))
 
Fold:  10
Average
Precision | Recall | F-Score
(0.585281227173119, 0.5540540540540541, 0.5448725122638166, None)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/jarokiam/thesis-env/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

By Severity
Precision | Recall | F-Score
(array([0.        , 0.5       , 0.59459459, 1.        ]),
 array([0.        , 0.54545455, 0.62857143, 0.16666667]),
 array([0.        , 0.52173913, 0.61111111, 0.28571429]),
 array([ 0, 33, 35,  6]))
-----EXPERIMENT  6  END-------

Fri Mar 15 08:37:49 2019
TOTAL RUNTIME:  850.9641735553741 s

