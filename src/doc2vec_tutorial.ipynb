{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec Automatic Bug Severity Prediction Model\n",
    "\n",
    "## Dataset\n",
    "Data from 6 NASA projects that have reported using PITS bug tracking system will be used to train and test this model. The dataset consists of bug reports that include the following information: **id**, **subject**, **severity**, **description** and **initiation date**.\n",
    "\n",
    "## Method\n",
    "1. Load data\n",
    "2. Create Training and Test Data\n",
    "3. Construct Doc2Vec Model\n",
    "4. Build Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path, sep=',', encoding='ISO-8859-1')\n",
    "    raw_data = np.array(df)\n",
    "    \n",
    "    # get the columns for Subject and Severity Rating\n",
    "    extract_cols = [1, 2]\n",
    "    del_cols = np.delete(np.arange(raw_data.shape[1]), extract_cols)\n",
    "    data = np.delete(raw_data, del_cols, axis=1)\n",
    "    \n",
    "    # check for possible NaN severity values\n",
    "    del_rows = []\n",
    "    for i in range(len(data)):\n",
    "        if math.isnan(data[i][1]):\n",
    "            del_rows.append(i)\n",
    "    \n",
    "    # delete rows that contain NaN severity values\n",
    "    if len(del_rows) > 0:\n",
    "        data = np.delete(data, del_rows, axis=0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset file locations\n",
    "pits_train = ['../dataset/raw/pitsA.csv',\n",
    "              '../dataset/raw/pitsB.csv',\n",
    "              '../dataset/raw/pitsC.csv',\n",
    "              '../dataset/raw/pitsD.csv',\n",
    "              '../dataset/raw/pitsE.csv',]\n",
    "\n",
    "pits_test = '../dataset/raw/pitsF.csv'\n",
    "\n",
    "# construct list of lines from the concatenation of datasets for training\n",
    "train_data = []\n",
    "for project in pits_train:\n",
    "    train_data.append(load_data(project))\n",
    "train_data = np.concatenate([project for project in train_data])\n",
    "\n",
    "# construct list of lines for testing\n",
    "test_data = load_data(pits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(data, tokens_only=False):\n",
    "    for i, line in enumerate(data):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(line[0])\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line[0]), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train_data))\n",
    "test_corpus = list(read_corpus(test_data, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=[u'build', u'unitialized', u'variables'], tags=[0]),\n",
       " TaggedDocument(words=[u'build', u'fsw', u'typecast', u'mismatch', u'in', u'memory', u'deallocation'], tags=[1])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of training corpus\n",
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'lack',\n",
       "  u'of',\n",
       "  u'verification',\n",
       "  u'of',\n",
       "  u'requirement',\n",
       "  u'fsw',\n",
       "  u'sn',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'pulse',\n",
       "  u'train',\n",
       "  u'firing',\n",
       "  u'thruster',\n",
       "  u'mode'],\n",
       " [u'lack',\n",
       "  u'of',\n",
       "  u'verification',\n",
       "  u'of',\n",
       "  u'requirement',\n",
       "  u'fsw',\n",
       "  u'sn',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'pulse',\n",
       "  u'train',\n",
       "  u'firing',\n",
       "  u'thruster',\n",
       "  u'mode']]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of testing corpus\n",
    "test_corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.94 s, sys: 1.93 s, total: 8.87 s\n",
      "Wall time: 5.84 s\n"
     ]
    }
   ],
   "source": [
    "# instantiate Doc2Vec object\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "\n",
    "# build a vocabulary\n",
    "model.build_vocab(train_corpus)\n",
    "\n",
    "# train model\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 546,\n",
       "         1: 214,\n",
       "         2: 94,\n",
       "         3: 72,\n",
       "         4: 69,\n",
       "         5: 52,\n",
       "         6: 46,\n",
       "         7: 30,\n",
       "         8: 28,\n",
       "         9: 19,\n",
       "         10: 23,\n",
       "         11: 33,\n",
       "         12: 24,\n",
       "         13: 24,\n",
       "         14: 17,\n",
       "         15: 15,\n",
       "         16: 20,\n",
       "         17: 15,\n",
       "         18: 24,\n",
       "         19: 8,\n",
       "         20: 8,\n",
       "         21: 13,\n",
       "         22: 13,\n",
       "         23: 17,\n",
       "         24: 6,\n",
       "         25: 15,\n",
       "         26: 16,\n",
       "         27: 10,\n",
       "         28: 5,\n",
       "         29: 17,\n",
       "         30: 11,\n",
       "         31: 6,\n",
       "         32: 5,\n",
       "         33: 6,\n",
       "         34: 5,\n",
       "         35: 6,\n",
       "         36: 8,\n",
       "         37: 7,\n",
       "         38: 13,\n",
       "         39: 6,\n",
       "         40: 2,\n",
       "         41: 5,\n",
       "         42: 9,\n",
       "         43: 8,\n",
       "         44: 6,\n",
       "         45: 2,\n",
       "         46: 11,\n",
       "         47: 9,\n",
       "         48: 8,\n",
       "         49: 5,\n",
       "         50: 5,\n",
       "         51: 5,\n",
       "         52: 1,\n",
       "         53: 3,\n",
       "         54: 7,\n",
       "         55: 6,\n",
       "         56: 2,\n",
       "         57: 8,\n",
       "         58: 4,\n",
       "         59: 4,\n",
       "         60: 2,\n",
       "         61: 5,\n",
       "         62: 2,\n",
       "         63: 6,\n",
       "         64: 3,\n",
       "         66: 1,\n",
       "         67: 3,\n",
       "         68: 6,\n",
       "         69: 4,\n",
       "         70: 2,\n",
       "         71: 4,\n",
       "         72: 2,\n",
       "         73: 4,\n",
       "         74: 4,\n",
       "         75: 5,\n",
       "         76: 5,\n",
       "         77: 2,\n",
       "         78: 1,\n",
       "         79: 5,\n",
       "         80: 3,\n",
       "         81: 7,\n",
       "         82: 3,\n",
       "         83: 5,\n",
       "         84: 5,\n",
       "         85: 2,\n",
       "         86: 3,\n",
       "         87: 4,\n",
       "         88: 4,\n",
       "         89: 1,\n",
       "         90: 2,\n",
       "         91: 2,\n",
       "         92: 3,\n",
       "         93: 3,\n",
       "         95: 4,\n",
       "         96: 2,\n",
       "         97: 3,\n",
       "         98: 1,\n",
       "         99: 3,\n",
       "         100: 4,\n",
       "         101: 4,\n",
       "         102: 4,\n",
       "         103: 3,\n",
       "         104: 3,\n",
       "         105: 3,\n",
       "         106: 5,\n",
       "         107: 4,\n",
       "         108: 2,\n",
       "         109: 1,\n",
       "         110: 2,\n",
       "         111: 3,\n",
       "         112: 1,\n",
       "         113: 3,\n",
       "         114: 3,\n",
       "         115: 5,\n",
       "         116: 3,\n",
       "         117: 4,\n",
       "         118: 3,\n",
       "         120: 2,\n",
       "         121: 3,\n",
       "         122: 6,\n",
       "         123: 3,\n",
       "         124: 1,\n",
       "         125: 4,\n",
       "         126: 1,\n",
       "         127: 3,\n",
       "         129: 2,\n",
       "         130: 3,\n",
       "         131: 1,\n",
       "         132: 6,\n",
       "         133: 2,\n",
       "         134: 4,\n",
       "         135: 2,\n",
       "         136: 1,\n",
       "         137: 4,\n",
       "         138: 1,\n",
       "         139: 2,\n",
       "         140: 3,\n",
       "         141: 1,\n",
       "         142: 3,\n",
       "         143: 3,\n",
       "         144: 2,\n",
       "         145: 4,\n",
       "         146: 1,\n",
       "         147: 4,\n",
       "         148: 2,\n",
       "         149: 1,\n",
       "         150: 2,\n",
       "         151: 3,\n",
       "         152: 3,\n",
       "         154: 2,\n",
       "         155: 1,\n",
       "         156: 3,\n",
       "         157: 4,\n",
       "         160: 1,\n",
       "         161: 1,\n",
       "         162: 1,\n",
       "         163: 1,\n",
       "         164: 4,\n",
       "         165: 2,\n",
       "         166: 1,\n",
       "         167: 3,\n",
       "         168: 3,\n",
       "         169: 1,\n",
       "         171: 1,\n",
       "         172: 1,\n",
       "         173: 2,\n",
       "         174: 2,\n",
       "         175: 5,\n",
       "         176: 1,\n",
       "         177: 2,\n",
       "         178: 4,\n",
       "         179: 1,\n",
       "         180: 3,\n",
       "         181: 1,\n",
       "         182: 2,\n",
       "         183: 1,\n",
       "         184: 1,\n",
       "         185: 2,\n",
       "         187: 1,\n",
       "         189: 1,\n",
       "         190: 3,\n",
       "         192: 1,\n",
       "         193: 1,\n",
       "         194: 1,\n",
       "         195: 4,\n",
       "         196: 4,\n",
       "         197: 1,\n",
       "         198: 2,\n",
       "         200: 2,\n",
       "         201: 1,\n",
       "         203: 2,\n",
       "         204: 3,\n",
       "         205: 3,\n",
       "         207: 1,\n",
       "         208: 1,\n",
       "         211: 2,\n",
       "         212: 1,\n",
       "         213: 2,\n",
       "         214: 2,\n",
       "         215: 3,\n",
       "         216: 1,\n",
       "         217: 4,\n",
       "         219: 3,\n",
       "         223: 2,\n",
       "         225: 2,\n",
       "         229: 4,\n",
       "         230: 1,\n",
       "         231: 2,\n",
       "         232: 2,\n",
       "         234: 1,\n",
       "         235: 3,\n",
       "         236: 3,\n",
       "         237: 1,\n",
       "         239: 1,\n",
       "         241: 4,\n",
       "         242: 2,\n",
       "         243: 2,\n",
       "         245: 1,\n",
       "         246: 3,\n",
       "         247: 1,\n",
       "         248: 2,\n",
       "         250: 2,\n",
       "         252: 1,\n",
       "         254: 3,\n",
       "         255: 1,\n",
       "         256: 2,\n",
       "         257: 1,\n",
       "         262: 1,\n",
       "         263: 1,\n",
       "         264: 3,\n",
       "         266: 1,\n",
       "         267: 1,\n",
       "         268: 2,\n",
       "         271: 3,\n",
       "         273: 2,\n",
       "         274: 3,\n",
       "         275: 1,\n",
       "         278: 2,\n",
       "         279: 1,\n",
       "         280: 3,\n",
       "         281: 2,\n",
       "         282: 1,\n",
       "         284: 4,\n",
       "         285: 1,\n",
       "         287: 1,\n",
       "         288: 1,\n",
       "         289: 1,\n",
       "         290: 1,\n",
       "         291: 1,\n",
       "         292: 2,\n",
       "         293: 1,\n",
       "         295: 1,\n",
       "         296: 2,\n",
       "         297: 1,\n",
       "         298: 1,\n",
       "         299: 3,\n",
       "         300: 5,\n",
       "         303: 2,\n",
       "         304: 2,\n",
       "         305: 3,\n",
       "         306: 1,\n",
       "         312: 2,\n",
       "         313: 2,\n",
       "         314: 1,\n",
       "         315: 1,\n",
       "         317: 1,\n",
       "         318: 2,\n",
       "         320: 2,\n",
       "         321: 2,\n",
       "         323: 1,\n",
       "         324: 1,\n",
       "         325: 1,\n",
       "         329: 1,\n",
       "         330: 1,\n",
       "         332: 3,\n",
       "         333: 1,\n",
       "         334: 2,\n",
       "         335: 1,\n",
       "         336: 2,\n",
       "         337: 2,\n",
       "         338: 2,\n",
       "         340: 2,\n",
       "         342: 1,\n",
       "         345: 1,\n",
       "         348: 1,\n",
       "         349: 1,\n",
       "         352: 1,\n",
       "         354: 1,\n",
       "         355: 1,\n",
       "         356: 1,\n",
       "         359: 1,\n",
       "         360: 1,\n",
       "         362: 1,\n",
       "         363: 1,\n",
       "         364: 1,\n",
       "         365: 2,\n",
       "         366: 1,\n",
       "         367: 2,\n",
       "         368: 4,\n",
       "         370: 1,\n",
       "         371: 1,\n",
       "         373: 2,\n",
       "         375: 1,\n",
       "         376: 2,\n",
       "         379: 1,\n",
       "         380: 1,\n",
       "         381: 1,\n",
       "         382: 1,\n",
       "         384: 1,\n",
       "         386: 1,\n",
       "         388: 2,\n",
       "         389: 2,\n",
       "         391: 2,\n",
       "         392: 2,\n",
       "         393: 1,\n",
       "         394: 1,\n",
       "         395: 1,\n",
       "         396: 2,\n",
       "         397: 1,\n",
       "         399: 1,\n",
       "         400: 1,\n",
       "         404: 1,\n",
       "         405: 1,\n",
       "         407: 1,\n",
       "         408: 1,\n",
       "         409: 1,\n",
       "         411: 1,\n",
       "         415: 2,\n",
       "         418: 3,\n",
       "         420: 2,\n",
       "         421: 1,\n",
       "         422: 1,\n",
       "         423: 1,\n",
       "         424: 2,\n",
       "         425: 1,\n",
       "         426: 1,\n",
       "         427: 1,\n",
       "         428: 2,\n",
       "         430: 1,\n",
       "         432: 1,\n",
       "         435: 1,\n",
       "         437: 1,\n",
       "         440: 1,\n",
       "         441: 1,\n",
       "         447: 1,\n",
       "         450: 2,\n",
       "         451: 1,\n",
       "         452: 1,\n",
       "         453: 2,\n",
       "         454: 1,\n",
       "         455: 2,\n",
       "         456: 3,\n",
       "         457: 1,\n",
       "         458: 1,\n",
       "         464: 1,\n",
       "         465: 1,\n",
       "         466: 1,\n",
       "         468: 3,\n",
       "         470: 1,\n",
       "         471: 2,\n",
       "         472: 1,\n",
       "         473: 1,\n",
       "         479: 2,\n",
       "         482: 2,\n",
       "         484: 1,\n",
       "         485: 2,\n",
       "         486: 1,\n",
       "         490: 1,\n",
       "         491: 1,\n",
       "         494: 1,\n",
       "         495: 1,\n",
       "         498: 1,\n",
       "         499: 1,\n",
       "         500: 1,\n",
       "         502: 2,\n",
       "         504: 1,\n",
       "         505: 1,\n",
       "         506: 3,\n",
       "         508: 1,\n",
       "         509: 1,\n",
       "         510: 1,\n",
       "         512: 3,\n",
       "         513: 2,\n",
       "         516: 1,\n",
       "         517: 1,\n",
       "         518: 4,\n",
       "         519: 1,\n",
       "         527: 1,\n",
       "         529: 3,\n",
       "         531: 1,\n",
       "         533: 1,\n",
       "         536: 2,\n",
       "         538: 2,\n",
       "         541: 1,\n",
       "         544: 1,\n",
       "         550: 1,\n",
       "         552: 1,\n",
       "         560: 2,\n",
       "         561: 1,\n",
       "         562: 1,\n",
       "         565: 1,\n",
       "         566: 1,\n",
       "         568: 1,\n",
       "         569: 3,\n",
       "         570: 1,\n",
       "         573: 1,\n",
       "         575: 1,\n",
       "         576: 3,\n",
       "         577: 2,\n",
       "         578: 2,\n",
       "         579: 1,\n",
       "         582: 1,\n",
       "         585: 3,\n",
       "         586: 1,\n",
       "         588: 1,\n",
       "         589: 1,\n",
       "         590: 2,\n",
       "         591: 1,\n",
       "         595: 1,\n",
       "         596: 1,\n",
       "         597: 2,\n",
       "         598: 1,\n",
       "         600: 2,\n",
       "         601: 1,\n",
       "         602: 2,\n",
       "         610: 1,\n",
       "         611: 1,\n",
       "         612: 1,\n",
       "         613: 1,\n",
       "         614: 2,\n",
       "         615: 1,\n",
       "         616: 2,\n",
       "         618: 1,\n",
       "         631: 2,\n",
       "         637: 3,\n",
       "         639: 2,\n",
       "         641: 1,\n",
       "         644: 1,\n",
       "         648: 1,\n",
       "         649: 1,\n",
       "         650: 1,\n",
       "         656: 1,\n",
       "         658: 2,\n",
       "         659: 1,\n",
       "         660: 2,\n",
       "         665: 1,\n",
       "         666: 2,\n",
       "         667: 1,\n",
       "         669: 2,\n",
       "         670: 1,\n",
       "         676: 1,\n",
       "         678: 1,\n",
       "         681: 2,\n",
       "         682: 2,\n",
       "         684: 1,\n",
       "         685: 2,\n",
       "         688: 1,\n",
       "         689: 1,\n",
       "         691: 1,\n",
       "         692: 2,\n",
       "         694: 3,\n",
       "         701: 1,\n",
       "         704: 1,\n",
       "         706: 1,\n",
       "         707: 1,\n",
       "         708: 1,\n",
       "         714: 1,\n",
       "         720: 2,\n",
       "         722: 1,\n",
       "         724: 1,\n",
       "         725: 1,\n",
       "         727: 1,\n",
       "         728: 1,\n",
       "         729: 1,\n",
       "         735: 1,\n",
       "         736: 1,\n",
       "         737: 1,\n",
       "         746: 1,\n",
       "         747: 1,\n",
       "         748: 1,\n",
       "         751: 1,\n",
       "         756: 2,\n",
       "         757: 1,\n",
       "         758: 2,\n",
       "         759: 4,\n",
       "         760: 1,\n",
       "         761: 1,\n",
       "         762: 1,\n",
       "         763: 1,\n",
       "         764: 2,\n",
       "         765: 1,\n",
       "         767: 1,\n",
       "         768: 1,\n",
       "         770: 1,\n",
       "         774: 1,\n",
       "         778: 3,\n",
       "         780: 2,\n",
       "         781: 2,\n",
       "         782: 1,\n",
       "         783: 5,\n",
       "         789: 2,\n",
       "         793: 1,\n",
       "         795: 4,\n",
       "         800: 1,\n",
       "         803: 3,\n",
       "         805: 2,\n",
       "         807: 2,\n",
       "         809: 1,\n",
       "         810: 2,\n",
       "         813: 1,\n",
       "         815: 3,\n",
       "         816: 1,\n",
       "         821: 1,\n",
       "         822: 1,\n",
       "         823: 1,\n",
       "         825: 1,\n",
       "         827: 1,\n",
       "         829: 1,\n",
       "         830: 1,\n",
       "         832: 1,\n",
       "         833: 1,\n",
       "         834: 1,\n",
       "         836: 2,\n",
       "         837: 1,\n",
       "         839: 2,\n",
       "         840: 1,\n",
       "         842: 2,\n",
       "         848: 1,\n",
       "         849: 1,\n",
       "         850: 3,\n",
       "         851: 1,\n",
       "         852: 1,\n",
       "         857: 3,\n",
       "         858: 1,\n",
       "         862: 1,\n",
       "         863: 3,\n",
       "         867: 1,\n",
       "         868: 1,\n",
       "         869: 2,\n",
       "         870: 2,\n",
       "         871: 1,\n",
       "         873: 1,\n",
       "         875: 1,\n",
       "         879: 1,\n",
       "         880: 1,\n",
       "         884: 1,\n",
       "         886: 2,\n",
       "         888: 1,\n",
       "         891: 2,\n",
       "         892: 1,\n",
       "         894: 1,\n",
       "         895: 1,\n",
       "         896: 1,\n",
       "         899: 2,\n",
       "         900: 1,\n",
       "         905: 4,\n",
       "         906: 2,\n",
       "         907: 1,\n",
       "         909: 1,\n",
       "         910: 1,\n",
       "         916: 1,\n",
       "         921: 1,\n",
       "         923: 2,\n",
       "         924: 1,\n",
       "         928: 1,\n",
       "         929: 1,\n",
       "         931: 1,\n",
       "         936: 1,\n",
       "         939: 2,\n",
       "         944: 2,\n",
       "         945: 1,\n",
       "         947: 1,\n",
       "         959: 1,\n",
       "         960: 1,\n",
       "         969: 3,\n",
       "         971: 2,\n",
       "         972: 1,\n",
       "         973: 1,\n",
       "         976: 1,\n",
       "         979: 1,\n",
       "         980: 3,\n",
       "         982: 3,\n",
       "         986: 1,\n",
       "         987: 1,\n",
       "         989: 1,\n",
       "         993: 1,\n",
       "         994: 1,\n",
       "         997: 1,\n",
       "         998: 2,\n",
       "         1000: 1,\n",
       "         1002: 1,\n",
       "         1004: 1,\n",
       "         1005: 1,\n",
       "         1006: 2,\n",
       "         1007: 1,\n",
       "         1009: 1,\n",
       "         1010: 1,\n",
       "         1011: 1,\n",
       "         1013: 1,\n",
       "         1014: 1,\n",
       "         1018: 1,\n",
       "         1024: 1,\n",
       "         1028: 1,\n",
       "         1040: 1,\n",
       "         1042: 1,\n",
       "         1044: 1,\n",
       "         1046: 1,\n",
       "         1047: 1,\n",
       "         1048: 2,\n",
       "         1049: 1,\n",
       "         1052: 1,\n",
       "         1053: 2,\n",
       "         1054: 1,\n",
       "         1055: 1,\n",
       "         1057: 1,\n",
       "         1058: 1,\n",
       "         1062: 1,\n",
       "         1067: 1,\n",
       "         1070: 2,\n",
       "         1073: 1,\n",
       "         1077: 1,\n",
       "         1078: 1,\n",
       "         1079: 1,\n",
       "         1080: 1,\n",
       "         1083: 1,\n",
       "         1084: 1,\n",
       "         1087: 1,\n",
       "         1090: 1,\n",
       "         1092: 1,\n",
       "         1093: 1,\n",
       "         1094: 2,\n",
       "         1095: 1,\n",
       "         1097: 1,\n",
       "         1099: 2,\n",
       "         1102: 1,\n",
       "         1103: 1,\n",
       "         1105: 1,\n",
       "         1106: 1,\n",
       "         1110: 1,\n",
       "         1123: 1,\n",
       "         1124: 1,\n",
       "         1125: 2,\n",
       "         1126: 1,\n",
       "         1127: 1,\n",
       "         1129: 1,\n",
       "         1131: 2,\n",
       "         1134: 1,\n",
       "         1136: 1,\n",
       "         1137: 1,\n",
       "         1143: 2,\n",
       "         1145: 1,\n",
       "         1146: 1,\n",
       "         1152: 1,\n",
       "         1157: 1,\n",
       "         1161: 1,\n",
       "         1164: 1,\n",
       "         1172: 2,\n",
       "         1174: 2,\n",
       "         1179: 1,\n",
       "         1180: 1,\n",
       "         1181: 1,\n",
       "         1182: 1,\n",
       "         1184: 1,\n",
       "         1185: 2,\n",
       "         1191: 1,\n",
       "         1192: 1,\n",
       "         1193: 1,\n",
       "         1197: 1,\n",
       "         1199: 1,\n",
       "         1203: 1,\n",
       "         1210: 1,\n",
       "         1212: 1,\n",
       "         1214: 1,\n",
       "         1215: 1,\n",
       "         1217: 1,\n",
       "         1219: 2,\n",
       "         1222: 1,\n",
       "         1225: 3,\n",
       "         1229: 1,\n",
       "         1232: 1,\n",
       "         1233: 1,\n",
       "         1242: 1,\n",
       "         1248: 1,\n",
       "         1253: 1,\n",
       "         1264: 1,\n",
       "         1266: 1,\n",
       "         1268: 1,\n",
       "         1270: 1,\n",
       "         1271: 1,\n",
       "         1277: 1,\n",
       "         1282: 1,\n",
       "         1283: 1,\n",
       "         1285: 1,\n",
       "         1294: 2,\n",
       "         1295: 1,\n",
       "         1297: 1,\n",
       "         1298: 1,\n",
       "         1299: 2,\n",
       "         1300: 1,\n",
       "         1303: 1,\n",
       "         1304: 1,\n",
       "         1305: 1,\n",
       "         1310: 1,\n",
       "         1311: 1,\n",
       "         1314: 2,\n",
       "         1316: 1,\n",
       "         1328: 2,\n",
       "         1329: 1,\n",
       "         1330: 1,\n",
       "         1333: 1,\n",
       "         1339: 1,\n",
       "         1340: 1,\n",
       "         1341: 1,\n",
       "         1347: 1,\n",
       "         1350: 2,\n",
       "         1353: 2,\n",
       "         1357: 2,\n",
       "         1359: 2,\n",
       "         1362: 1,\n",
       "         1363: 2,\n",
       "         1365: 1,\n",
       "         1367: 1,\n",
       "         1369: 1,\n",
       "         1371: 1,\n",
       "         1372: 1,\n",
       "         1377: 1,\n",
       "         1382: 1,\n",
       "         1383: 4,\n",
       "         1384: 1,\n",
       "         1386: 1,\n",
       "         1389: 1,\n",
       "         1393: 1,\n",
       "         1394: 1,\n",
       "         1404: 2,\n",
       "         1405: 1,\n",
       "         1406: 1,\n",
       "         1407: 1,\n",
       "         1408: 2,\n",
       "         1414: 1,\n",
       "         1415: 2,\n",
       "         1419: 1,\n",
       "         1420: 1,\n",
       "         1421: 1,\n",
       "         1422: 1,\n",
       "         1427: 1,\n",
       "         1432: 2,\n",
       "         1433: 1,\n",
       "         1440: 1,\n",
       "         1442: 1,\n",
       "         1444: 1,\n",
       "         1446: 1,\n",
       "         1453: 1,\n",
       "         1454: 2,\n",
       "         1460: 1,\n",
       "         1464: 1,\n",
       "         1468: 2,\n",
       "         1469: 1,\n",
       "         1470: 2,\n",
       "         1471: 1,\n",
       "         1474: 1,\n",
       "         1475: 1,\n",
       "         1478: 1,\n",
       "         1480: 2,\n",
       "         1482: 1,\n",
       "         1483: 2,\n",
       "         1484: 1,\n",
       "         1488: 1,\n",
       "         1489: 1,\n",
       "         1492: 1,\n",
       "         1494: 1,\n",
       "         1498: 1,\n",
       "         1503: 2,\n",
       "         1510: 1,\n",
       "         1512: 1,\n",
       "         1513: 1,\n",
       "         1515: 2,\n",
       "         1522: 2,\n",
       "         1523: 1,\n",
       "         1527: 1,\n",
       "         1532: 1,\n",
       "         1535: 2,\n",
       "         1536: 2,\n",
       "         1537: 1,\n",
       "         1538: 1,\n",
       "         1541: 2,\n",
       "         1543: 1,\n",
       "         1544: 1,\n",
       "         1545: 1,\n",
       "         1547: 1,\n",
       "         1549: 2,\n",
       "         1553: 1,\n",
       "         1557: 1,\n",
       "         1558: 1,\n",
       "         1559: 1,\n",
       "         1562: 2,\n",
       "         1565: 1,\n",
       "         1566: 1,\n",
       "         1571: 1,\n",
       "         1580: 1,\n",
       "         1584: 1,\n",
       "         1589: 1,\n",
       "         1593: 1,\n",
       "         1597: 2,\n",
       "         1598: 1,\n",
       "         1599: 1,\n",
       "         1600: 1,\n",
       "         1602: 1,\n",
       "         1604: 1,\n",
       "         1606: 1,\n",
       "         1609: 1,\n",
       "         1615: 1,\n",
       "         1616: 1,\n",
       "         1620: 2,\n",
       "         1624: 2,\n",
       "         1626: 2,\n",
       "         1627: 1,\n",
       "         1629: 1,\n",
       "         1630: 1,\n",
       "         1633: 1,\n",
       "         1634: 1,\n",
       "         1639: 1,\n",
       "         1640: 2,\n",
       "         1641: 1,\n",
       "         1649: 1,\n",
       "         1654: 2,\n",
       "         1660: 1,\n",
       "         1664: 1,\n",
       "         1665: 1,\n",
       "         1666: 1,\n",
       "         1668: 2,\n",
       "         1676: 2,\n",
       "         1682: 1,\n",
       "         1686: 1,\n",
       "         1689: 1,\n",
       "         1693: 1,\n",
       "         1705: 1,\n",
       "         1707: 1,\n",
       "         1709: 1,\n",
       "         1711: 1,\n",
       "         1716: 1,\n",
       "         1719: 1,\n",
       "         1726: 1,\n",
       "         1730: 2,\n",
       "         1733: 1,\n",
       "         1734: 1,\n",
       "         1735: 1,\n",
       "         1739: 1,\n",
       "         1740: 1,\n",
       "         1743: 1,\n",
       "         1744: 1,\n",
       "         1745: 1,\n",
       "         1747: 1,\n",
       "         1749: 1,\n",
       "         1751: 1,\n",
       "         1755: 1,\n",
       "         1757: 2,\n",
       "         1759: 1,\n",
       "         1760: 1,\n",
       "         1761: 1,\n",
       "         1767: 1,\n",
       "         1768: 1,\n",
       "         1771: 1,\n",
       "         1773: 1,\n",
       "         1784: 2,\n",
       "         1785: 1,\n",
       "         1790: 1,\n",
       "         1807: 1,\n",
       "         1808: 2,\n",
       "         1809: 1,\n",
       "         1815: 1,\n",
       "         1817: 1,\n",
       "         1818: 2,\n",
       "         1822: 1,\n",
       "         1824: 1,\n",
       "         1826: 1,\n",
       "         1832: 1,\n",
       "         1834: 1,\n",
       "         1838: 2,\n",
       "         1842: 1,\n",
       "         1843: 2,\n",
       "         1855: 1,\n",
       "         1862: 3,\n",
       "         1864: 1,\n",
       "         1868: 1,\n",
       "         1872: 1,\n",
       "         1878: 1,\n",
       "         1879: 1,\n",
       "         1882: 1,\n",
       "         1889: 1,\n",
       "         1891: 1,\n",
       "         1894: 1,\n",
       "         1896: 1,\n",
       "         1899: 1,\n",
       "         1902: 1,\n",
       "         1903: 1,\n",
       "         1904: 1,\n",
       "         1908: 1,\n",
       "         1917: 1,\n",
       "         1919: 1,\n",
       "         1923: 1,\n",
       "         1927: 1,\n",
       "         1929: 1,\n",
       "         1937: 2,\n",
       "         1938: 1,\n",
       "         1943: 1,\n",
       "         1944: 1,\n",
       "         1945: 1,\n",
       "         1947: 1,\n",
       "         1949: 1,\n",
       "         1956: 1,\n",
       "         1957: 1,\n",
       "         1958: 1,\n",
       "         1959: 1,\n",
       "         1960: 1,\n",
       "         1965: 1,\n",
       "         1966: 1,\n",
       "         1967: 1,\n",
       "         1977: 1,\n",
       "         1978: 1,\n",
       "         1984: 2,\n",
       "         1987: 1,\n",
       "         1989: 1,\n",
       "         1990: 1,\n",
       "         1991: 1,\n",
       "         1992: 1,\n",
       "         1996: 1,\n",
       "         2002: 1,\n",
       "         2003: 1,\n",
       "         2021: 1,\n",
       "         2022: 1,\n",
       "         2030: 1,\n",
       "         2033: 1,\n",
       "         2036: 1,\n",
       "         2038: 3,\n",
       "         2041: 1,\n",
       "         2044: 1,\n",
       "         2054: 1,\n",
       "         2061: 1,\n",
       "         2064: 2,\n",
       "         2070: 1,\n",
       "         2076: 1,\n",
       "         2080: 3,\n",
       "         2081: 1,\n",
       "         2082: 1,\n",
       "         2083: 1,\n",
       "         2084: 2,\n",
       "         2086: 1,\n",
       "         2087: 2,\n",
       "         2089: 2,\n",
       "         2090: 1,\n",
       "         2095: 1,\n",
       "         2104: 1,\n",
       "         2108: 1,\n",
       "         2111: 1,\n",
       "         2115: 1,\n",
       "         2116: 1,\n",
       "         2119: 1,\n",
       "         2120: 1,\n",
       "         2121: 1,\n",
       "         2123: 1,\n",
       "         2127: 1,\n",
       "         2136: 1,\n",
       "         2138: 1,\n",
       "         2140: 1,\n",
       "         2141: 1,\n",
       "         2143: 1,\n",
       "         2146: 1,\n",
       "         2149: 1,\n",
       "         2156: 1,\n",
       "         2169: 1,\n",
       "         2170: 1,\n",
       "         2171: 1,\n",
       "         2172: 2,\n",
       "         2181: 1,\n",
       "         2184: 1,\n",
       "         2187: 2,\n",
       "         2190: 1,\n",
       "         2191: 1,\n",
       "         2194: 2,\n",
       "         2197: 1,\n",
       "         2203: 1,\n",
       "         2207: 1,\n",
       "         2210: 1,\n",
       "         2217: 2,\n",
       "         2230: 1,\n",
       "         2238: 1,\n",
       "         2239: 1,\n",
       "         2246: 1,\n",
       "         2255: 1,\n",
       "         2263: 1,\n",
       "         2266: 1,\n",
       "         2270: 2,\n",
       "         2271: 1,\n",
       "         2278: 1,\n",
       "         2287: 1,\n",
       "         2289: 1,\n",
       "         2291: 1,\n",
       "         2294: 1,\n",
       "         2295: 1,\n",
       "         2297: 2,\n",
       "         ...})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks)  # Results vary between runs due to random seeding and very small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (3281): «vague configurable parameters in section»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (357, 0.866884708404541): «engcntrl test scripts engcntrl srs requirement inconsistent with rvm and fsw_test_»\n",
      "\n",
      "SECOND-MOST (366, 0.8561243414878845): «engcntrl test scripts engcntrl srs requirement inconsistent with rvm and fsw_test_»\n",
      "\n",
      "MEDIAN (1873, 0.5102684497833252): «xb test scenario review verification method for requirement is questionable»\n",
      "\n",
      "LEAST (2740, -0.6542261242866516): «inst test case tc_inst does not trace to srs and is missing trace»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (554): «build obc code testing floats for equality in function ac_slewsetup»\n",
      "\n",
      "Similar Document (1321, 0.8426072597503662): «code review dss digital sun sensor build feb no evidence found for converting the dss output to decimal values»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (638): «click»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (2702, 0.38667237758636475): «inst test cases and contain possible errors»\n",
      "\n",
      "MEDIAN (3021, -0.07608343660831451): «level fsw requirement is vaguely worded»\n",
      "\n",
      "LEAST (666, -0.42191559076309204): «prd is not linked to sc fs rqts»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "\n",
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u\"464-FSW-SPEC-0050 ACS FSW Requirements do not distinguish between 'Cold Restart' and 'Power On'\",\n",
       "       3.0], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare severity to similar doc\n",
    "train_data[1799]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'FSW.TP.06.06: Source inspection is inadequate to verify requirement',\n",
       "       3], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3282"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a Better Doc2Vec Model\n",
    "There are two types of paragraph vector models that can be used: disttibuted memory **(DM)** and distributed bag of words **(DBOW)**. In the orginal paper, _Distributed Representations of Sentences and Documents_, both models were introduced and experimented on. Their conclusion was that both models perform well for cetain datasets and should be chosen accordingly. The recommendation was to combine both models for the best results.\n",
    "\n",
    "We have chosen to follow the recommendation as a starting point when constructing our model. Further exploration can be done in the window size and individually use each model over the combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# instantiate Doc2Vec object\n",
    "model_DM = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40, workers=cores,  dm=1, dm_concat=1 )\n",
    "model_DBOW = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40, workers=cores, dm=0)\n",
    "\n",
    "# build a vocabulary\n",
    "model_DM.build_vocab(train_corpus)\n",
    "model_DBOW.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.16 s, sys: 1.28 s, total: 7.44 s\n",
      "Wall time: 3.91 s\n",
      "CPU times: user 4.65 s, sys: 1.32 s, total: 5.96 s\n",
      "Wall time: 3.72 s\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "%time model_DM.train(train_corpus, total_examples=model_DM.corpus_count, epochs=model_DM.epochs)\n",
    "%time model_DBOW.train(train_corpus, total_examples=model_DBOW.corpus_count, epochs=model_DBOW.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Classifier\n",
    "The original Paper, _\"Automated severity assessment of software defect reports\"_ uses the RIPPER rule learning algorithm to perform severity prediction. A follow up paper, _\"Prediction of defect severity by mining software project reports\"_, extends the original method by applying both DT and MLP.\n",
    "\n",
    "We have opted to use MLP to perform our predictions using the paragragh vectors produced by our Doc2Vec models. Rule learning and DT both performed well at the project level but, as highlighted in the above papers, rely on project specific data and thus do not generalize well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and train sets using Doc2Vec output\n",
    "X_train = [(list(model_DM.docvecs[i]) + list(model_DBOW.docvecs[i])) for i in range(len(train_data))]\n",
    "Y_train = [doc[1] for doc in train_data]\n",
    "\n",
    "X_test = [(list(model_DM.infer_vector(test_corpus[i])) + list(model_DBOW.infer_vector(test_corpus[i]))) for i in range(len(test_data))]\n",
    "Y_test = [doc[1] for doc in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  classifier  train_score  test_score\n",
      "1        MLP     0.669714    0.630376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(alpha = 0.7, max_iter=10000) \n",
    "#classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,solver='sgd', random_state=21,tol=0.000000001)\n",
    "classifier.fit(X_train, Y_train)\n",
    " \n",
    "df_results = pd.DataFrame(data=np.zeros(shape=(0,3)), columns = ['classifier', 'train_score', 'test_score'] )\n",
    "train_score = classifier.score(X_train, Y_train)\n",
    "test_score = classifier.score(X_test, Y_test)\n",
    " \n",
    "#print  (classifier.predict_proba(X_test))\n",
    "#print  (classifier.predict(X_test))\n",
    " \n",
    "df_results.loc[1,'classifier'] = \"MLP\"\n",
    "df_results.loc[1,'train_score'] = train_score\n",
    "df_results.loc[1,'test_score'] = test_score\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
