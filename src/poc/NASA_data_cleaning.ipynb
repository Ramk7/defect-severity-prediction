{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The process flow:\n",
    "1. Clean data\n",
    "2. Run data through Weka tool\n",
    "3. Record Results\n",
    "\n",
    "#### Assumptions\n",
    "* Due to sev 1 and 5 rarely occurring we have chosen not to include the test data initially \n",
    "\n",
    "\n",
    "_Google Style Python Docstrings have been used for documentation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "The Weka tool will be taking care of most of the preprocessing required such as:\n",
    "* Tokenization\n",
    "* Stop Word Removal\n",
    "* Stemming\n",
    "* Tf-Idf\n",
    "* InfoGain\n",
    "\n",
    "Weka can also randomize and split the dataset into training and testing sets.\n",
    "\n",
    "Before feeding the data into Weka, unneeded columns from the dataset must be removed. Of the remaining columns we should also ensure that the formatting meets the ARFF file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw dataset\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Loads file data and removes unneeded columns.\n",
    "    \n",
    "    Args:\n",
    "        path: The file path of the file being opened\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of the 'Subject' and 'Severity Rating' columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=',', encoding='ISO-8859-1')\n",
    "    raw_data = np.array(df)\n",
    "    \n",
    "    # get the columns for Subject and Severity Rating\n",
    "    extract_cols = [1, 2]\n",
    "    del_cols = np.delete(np.arange(raw_data.shape[1]), extract_cols)\n",
    "    data = np.delete(raw_data, del_cols, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_punctuation(data):\n",
    "    punctuations = '''!()[]{};:'\"\\,<>./?@#$%^&*~'''\n",
    "    \n",
    "    \n",
    "    # convert all letters to lowercase\n",
    "    lowercase_string = data.lower()\n",
    "    \n",
    "    # replace all punctuation with spaces\n",
    "    remove_punctuation = ''\n",
    "    for char in lowercase_string:\n",
    "        if char in punctuations:\n",
    "            remove_punctuation += ' '\n",
    "        else:\n",
    "            remove_punctuation += char\n",
    "    \n",
    "    return remove_punctuation\n",
    "\n",
    "# text-based columns\n",
    "def add_quotes(data):\n",
    "    \"\"\"Inserts surrounding quotes to the Summary column\n",
    "    \n",
    "    Args:\n",
    "        data: An n*m matrix where n is the number of rows in the dataset\n",
    "              and m is columns: 'Summary' and 'Severity Rating'. \n",
    "              \n",
    "              For example:\n",
    "              [['Build 5.3: Unitialized Variables' 3]\n",
    "              ['Build 5.3 FSW: Typecast Mismatch in Memory Deallocation' 3]\n",
    "              ['Build 5.3 FSW: Parameter Type Mismatch' 3]]\n",
    " \n",
    "    \n",
    "    Returns:\n",
    "        An n*m matrix where n is the number of rows in the dataset\n",
    "        and m is columns: 'Summary' and 'Severity Rating'.\n",
    "    \"\"\"\n",
    "    for x in data:\n",
    "        # remove punctuation and surround by single quotes\n",
    "        x[0] = no_punctuation(x[0])\n",
    "        x[0] = '\\''+ x[0] + '\\''\n",
    "        \n",
    "        # convert float severity ratings to int\n",
    "        x[1] = int(x[1])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output ARFF file\n",
    "def generate_arff(data):\n",
    "    output_path = '../output/output.arff'\n",
    "    output_file = open(output_path, 'w')\n",
    "    \n",
    "    # write header\n",
    "    output_file.write('@relation nasa\\n')\n",
    "    output_file.write('@attribute Text string\\n')\n",
    "    output_file.write('@attribute class-att {1, 2, 3, 4, 5}\\n\\n')\n",
    "    output_file.write('@data\\n\\n')\n",
    "    \n",
    "    # write data\n",
    "    for x in data:\n",
    "        line = x[0] + ',' + str(x[1]) + '\\n'\n",
    "        output_file.write(line)\n",
    "    \n",
    "    # close file\n",
    "    output_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "raw_data = load_data('../dataset/raw/pitsC.csv')\n",
    "cleaned_data = add_quotes(raw_data)\n",
    "generate_arff(cleaned_data)\n",
    "\n",
    "#pprint(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
